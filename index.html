<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="author" content="Rick O. Gilmore" />
  <title>Making cognitive science even better</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="libs/reveal.js-3.3.0.1/css/reveal.css"/>



<link rel="stylesheet" href="libs/reveal.js-3.3.0.1/css/theme/simple.css" id="theme">


  <!-- some tweaks to reveal css -->
  <style type="text/css">
    .reveal h1 { font-size: 2.0em; }
    .reveal h2 { font-size: 1.5em;  }
    .reveal h3 { font-size: 1.25em;	}
    .reveal h4 { font-size: 1em;	}

    .reveal .slides>section,
    .reveal .slides>section>section {
      padding: 0px 0px;
    }



    .reveal table {
      border-width: 1px;
      border-spacing: 2px;
      border-style: dotted;
      border-color: gray;
      border-collapse: collapse;
      font-size: 0.7em;
    }

    .reveal table th {
      border-width: 1px;
      padding-left: 10px;
      padding-right: 25px;
      font-weight: bold;
      border-style: dotted;
      border-color: gray;
    }

    .reveal table td {
      border-width: 1px;
      padding-left: 10px;
      padding-right: 25px;
      border-style: dotted;
      border-color: gray;
    }


  </style>

    <style type="text/css">code{white-space: pre;}</style>

    <link rel="stylesheet" href="styles.css"/>

<!-- Printing and PDF exports -->
<script id="paper-css" type="application/dynamic-css">

/* Default Print Stylesheet Template
   by Rob Glazebrook of CSSnewbie.com
   Last Updated: June 4, 2008

   Feel free (nay, compelled) to edit, append, and
   manipulate this file as you see fit. */


@media print {

	/* SECTION 1: Set default width, margin, float, and
	   background. This prevents elements from extending
	   beyond the edge of the printed page, and prevents
	   unnecessary background images from printing */
	html {
		background: #fff;
		width: auto;
		height: auto;
		overflow: visible;
	}
	body {
		background: #fff;
		font-size: 20pt;
		width: auto;
		height: auto;
		border: 0;
		margin: 0 5%;
		padding: 0;
		overflow: visible;
		float: none !important;
	}

	/* SECTION 2: Remove any elements not needed in print.
	   This would include navigation, ads, sidebars, etc. */
	.nestedarrow,
	.controls,
	.fork-reveal,
	.share-reveal,
	.state-background,
	.reveal .progress,
	.reveal .backgrounds {
		display: none !important;
	}

	/* SECTION 3: Set body font face, size, and color.
	   Consider using a serif font for readability. */
	body, p, td, li, div {
		font-size: 20pt!important;
		font-family: Georgia, "Times New Roman", Times, serif !important;
		color: #000;
	}

	/* SECTION 4: Set heading font face, sizes, and color.
	   Differentiate your headings from your body text.
	   Perhaps use a large sans-serif for distinction. */
	h1,h2,h3,h4,h5,h6 {
		color: #000!important;
		height: auto;
		line-height: normal;
		font-family: Georgia, "Times New Roman", Times, serif !important;
		text-shadow: 0 0 0 #000 !important;
		text-align: left;
		letter-spacing: normal;
	}
	/* Need to reduce the size of the fonts for printing */
	h1 { font-size: 28pt !important;  }
	h2 { font-size: 24pt !important; }
	h3 { font-size: 22pt !important; }
	h4 { font-size: 22pt !important; font-variant: small-caps; }
	h5 { font-size: 21pt !important; }
	h6 { font-size: 20pt !important; font-style: italic; }

	/* SECTION 5: Make hyperlinks more usable.
	   Ensure links are underlined, and consider appending
	   the URL to the end of the link for usability. */
	a:link,
	a:visited {
		color: #000 !important;
		font-weight: bold;
		text-decoration: underline;
	}
	/*
	.reveal a:link:after,
	.reveal a:visited:after {
		content: " (" attr(href) ") ";
		color: #222 !important;
		font-size: 90%;
	}
	*/


	/* SECTION 6: more reveal.js specific additions by @skypanther */
	ul, ol, div, p {
		visibility: visible;
		position: static;
		width: auto;
		height: auto;
		display: block;
		overflow: visible;
		margin: 0;
		text-align: left !important;
	}
	.reveal pre,
	.reveal table {
		margin-left: 0;
		margin-right: 0;
	}
	.reveal pre code {
		padding: 20px;
		border: 1px solid #ddd;
	}
	.reveal blockquote {
		margin: 20px 0;
	}
	.reveal .slides {
		position: static !important;
		width: auto !important;
		height: auto !important;

		left: 0 !important;
		top: 0 !important;
		margin-left: 0 !important;
		margin-top: 0 !important;
		padding: 0 !important;
		zoom: 1 !important;

		overflow: visible !important;
		display: block !important;

		text-align: left !important;
		-webkit-perspective: none;
		   -moz-perspective: none;
		    -ms-perspective: none;
		        perspective: none;

		-webkit-perspective-origin: 50% 50%;
		   -moz-perspective-origin: 50% 50%;
		    -ms-perspective-origin: 50% 50%;
		        perspective-origin: 50% 50%;
	}
	.reveal .slides section {
		visibility: visible !important;
		position: static !important;
		width: auto !important;
		height: auto !important;
		display: block !important;
		overflow: visible !important;

		left: 0 !important;
		top: 0 !important;
		margin-left: 0 !important;
		margin-top: 0 !important;
		padding: 60px 20px !important;
		z-index: auto !important;

		opacity: 1 !important;

		page-break-after: always !important;

		-webkit-transform-style: flat !important;
		   -moz-transform-style: flat !important;
		    -ms-transform-style: flat !important;
		        transform-style: flat !important;

		-webkit-transform: none !important;
		   -moz-transform: none !important;
		    -ms-transform: none !important;
		        transform: none !important;

		-webkit-transition: none !important;
		   -moz-transition: none !important;
		    -ms-transition: none !important;
		        transition: none !important;
	}
	.reveal .slides section.stack {
		padding: 0 !important;
	}
	.reveal section:last-of-type {
		page-break-after: avoid !important;
	}
	.reveal section .fragment {
		opacity: 1 !important;
		visibility: visible !important;

		-webkit-transform: none !important;
		   -moz-transform: none !important;
		    -ms-transform: none !important;
		        transform: none !important;
	}
	.reveal section img {
		display: block;
		margin: 15px 0px;
		background: rgba(255,255,255,1);
		border: 1px solid #666;
		box-shadow: none;
	}

	.reveal section small {
		font-size: 0.8em;
	}

}  
</script>


<script id="pdf-css" type="application/dynamic-css">
    
/**
 * This stylesheet is used to print reveal.js
 * presentations to PDF.
 *
 * https://github.com/hakimel/reveal.js#pdf-export
 */

* {
	-webkit-print-color-adjust: exact;
}

body {
	margin: 0 auto !important;
	border: 0;
	padding: 0;
	float: none !important;
	overflow: visible;
}

html {
	width: 100%;
	height: 100%;
	overflow: visible;
}

/* Remove any elements not needed in print. */
.nestedarrow,
.reveal .controls,
.reveal .progress,
.reveal .playback,
.reveal.overview,
.fork-reveal,
.share-reveal,
.state-background {
	display: none !important;
}

h1, h2, h3, h4, h5, h6 {
	text-shadow: 0 0 0 #000 !important;
}

.reveal pre code {
	overflow: hidden !important;
	font-family: Courier, 'Courier New', monospace !important;
}

ul, ol, div, p {
	visibility: visible;
	position: static;
	width: auto;
	height: auto;
	display: block;
	overflow: visible;
	margin: auto;
}
.reveal {
	width: auto !important;
	height: auto !important;
	overflow: hidden !important;
}
.reveal .slides {
	position: static;
	width: 100%;
	height: auto;

	left: auto;
	top: auto;
	margin: 0 !important;
	padding: 0 !important;

	overflow: visible;
	display: block;

	-webkit-perspective: none;
	   -moz-perspective: none;
	    -ms-perspective: none;
	        perspective: none;

	-webkit-perspective-origin: 50% 50%; /* there isn't a none/auto value but 50-50 is the default */
	   -moz-perspective-origin: 50% 50%;
	    -ms-perspective-origin: 50% 50%;
	        perspective-origin: 50% 50%;
}

.reveal .slides section {
	page-break-after: always !important;

	visibility: visible !important;
	position: relative !important;
	display: block !important;
	position: relative !important;

	margin: 0 !important;
	padding: 0 !important;
	box-sizing: border-box !important;
	min-height: 1px;

	opacity: 1 !important;

	-webkit-transform-style: flat !important;
	   -moz-transform-style: flat !important;
	    -ms-transform-style: flat !important;
	        transform-style: flat !important;

	-webkit-transform: none !important;
	   -moz-transform: none !important;
	    -ms-transform: none !important;
	        transform: none !important;
}

.reveal section.stack {
	margin: 0 !important;
	padding: 0 !important;
	page-break-after: avoid !important;
	height: auto !important;
	min-height: auto !important;
}

.reveal img {
	box-shadow: none;
}

.reveal .roll {
	overflow: visible;
	line-height: 1em;
}

/* Slide backgrounds are placed inside of their slide when exporting to PDF */
.reveal section .slide-background {
	display: block !important;
	position: absolute;
	top: 0;
	left: 0;
	width: 100%;
	z-index: -1;
}

/* All elements should be above the slide-background */
.reveal section>* {
	position: relative;
	z-index: 1;
}

/* Display slide speaker notes when 'showNotes' is enabled */
.reveal .speaker-notes-pdf {
	display: block;
	width: 100%;
	max-height: none;
	left: auto;
	top: auto;
	z-index: 100;
}

/* Display slide numbers when 'slideNumber' is enabled */
.reveal .slide-number-pdf {
	display: block;
	position: absolute;
	font-size: 14px;
}

</script>


<script>
var style = document.createElement( 'style' );
style.type = 'text/css';
var style_script_id = window.location.search.match( /print-pdf/gi ) ? 'pdf-css' : 'paper-css';
var style_script = document.getElementById(style_script_id).text;
style.innerHTML = style_script;
document.getElementsByTagName('head')[0].appendChild(style);
</script>

</head>
<body>
  <div class="reveal">
    <div class="slides">

<section>
    <h1 class="title">Making cognitive science even better</h1>
    <h2 class="author">Rick O. Gilmore</h2>
    <h3 class="date">2019-06-03 07:06:14</h3>
</section>

<section><section id="preliminaries" class="titleslide slide level1"><h1>Preliminaries</h1></section><section class="slide level2">

<p><img src="https://upload.wikimedia.org/wikipedia/commons/8/87/NSF_Logo.PNG" height=150px> <img src="https://pbs.twimg.com/profile_images/826768222363975680/8hO9VaFD.jpg" height=150px> </br> <img src="https://sloan.org/storage/app/media/Logos/Sloan-Logo-stacked-black-web.png" height=150px> <img src="http://newsroom.unl.edu/announce/files/file77330.jpg" height=150px/> <img src="https://www.unicef.org.hk/wp-content/uploads/2017/08/Logo-05_Lego-foundation_UNICEF_partnership.jpg" height=150px /> </br> <img src="https://nationalpress.org/wp-content/uploads/2016/04/NIDA-logo-300x300.jpg" height=150px/> <img src="http://bewellva.com/wp-content/uploads/2017/12/NIMH-Logo_14-e1510955490255.jpg" height=150px/> <img src="https://www.jsmf.org/assets/logo-small.png" height=150px/></p>
<!-- Funding sources with icons -->
<aside class="notes">
<p>I want to thank NSF, NIH, the Alfred P. Sloan Foundation, SRCD, the LEGO Foundation, and the James S. McDonnell Foundation for support.</p>
</aside>
</section><section class="slide level2">

<p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/0/0b/DenverCP.JPG/266px-DenverCP.JPG" height=150px/> <img src="http://watson.brown.edu/ds/sites/all/themes/ds/img/header/brown_large.png" height=150px/> <img src="https://www.wheretraveler.com/sites/default/files/styles/wt17_promoted/public/WashingtonDC-shutterstock_93633676.jpg?itok=IT7CL9PU" height=150px/> <img src="https://ai.cs.cmu.edu/sites/default/files/CMU.png" height=150px/> <img src="http://onwardstate.com/wp-content/uploads/2014/10/93" height=150px/> <img src="img/sleic.jpg" height=150px/></br> <img src="https://nyu.databrary.org/web/images/logo/databrary-nav.svg" height=150px></p>
<!-- Photo montage of ROG background -->
<!-- As brief background, I grew up in Denver, studied cognitive science at Brown, worked in non-profit management in DC before completing my Ph.D. in developmental cognitive neuroscience at Carnegie Mellon. -->
<!-- That's where I met Karen Adolph. -->
<!-- I moved to Penn State after finishing my degree. -->
<!-- I'm an infrastructure guy. -->
<!-- I founded Penn State's imaging center, and I am the co-founder and co-director of Databrary. -->
<aside class="notes">
<p>This is a brief bio in photos. As brief background, I grew up in Denver, studied cognitive science at Brown, worked in non-profit management in DC before completing my Ph.D. in developmental cognitive neuroscience at Carnegie Mellon. That’s where I met Karen Adolph. I moved to Penn State after finishing my degree. In addition to building my own line of work in visual development and neuroscience, I founded Penn State’s imaging center, and I am the co-founder and co-director of Databrary.</p>
</aside>
</section><section id="overview" class="slide level2">
<h2>Overview</h2>
<ul>
<li>The hardest science</li>
<li>Why it’s hard</li>
<li>Making cognitive science even better</li>
</ul>
<!-- Today I'm delighted to have the opportunity to share a few thoughts about how understanding how and why the science of human behavior is so hard will help research sponsors like JSMF accelerate progress. -->
<aside class="notes">
<p>Today I’m delighted to have the opportunity to share a few thoughts with you about why the science of human thought and behavior is so challenging and how reflecting on its challenges can make the science better. [RIGHT]</p>
</aside>
</section></section>
<section><section id="psychology-is-the-hardest-science" class="titleslide slide level1"><h1>Psychology is the hardest science</h1></section><section id="harder-than-physics" class="slide level2">
<h2>(Harder than physics)</h2>
<aside class="notes">
<p>Harder than physics. I suspect most of the people in this room agree, but in case there are skeptics, let me try to convince you in two simple figures.</p>
</aside>
</section><section class="slide level2">

<p><img src="img/psych-harder-1.jpg" height=500px/></p>
<!-- First year physical science students often face problems like this. Given a mass M, an inclined plane with specified geometry, and a gravitational field, we can predict the future with high precision. What's going to happen next? -->
<!-- Yes, but if we change one element in this equation, the problem becomes immensely harder. What if we change the mass to a mouse? -->
<aside class="notes">
<p>First year physical science students often face problems like this. Given a mass M, an inclined plane with specified geometry, and a gravitational field, we can predict the future with high precision. What’s going to happen next?</p>
<p>Yes, but if we change one element in this equation, the problem becomes immensely harder. What if we change the mass to a mouse?</p>
</aside>
</section><section class="slide level2">

<p><img src="img/psych-harder-2.jpg" height=500px/></p>
<!-- What happens now? We don't know. -->
<aside class="notes">
<p>What happens now? We don’t have a clue! Even asking the question seems humorous.</p>
<p>[RIGHT]</p>
<p>Let’s examine why it’s so hard.</p>
</aside>
</section></section>
<section><section id="why-its-hard" class="titleslide slide level1"><h1>Why it’s hard</h1></section><section class="slide level2">

<p><img src="http://cdn2.hubspot.net/hub/134568/file-1208368053-jpg/6-blind-men-hans.jpg" height=550px></p>
<!-- The whole elephant -->
<aside class="notes">
<p>This figure depicts the classic Hindu myth of the blind men examining an elephant. To me, it also reflects the state of psychological science.</p>
<p>We’re all studying the elephant, or so we say, but we might easily mistake the trunk for a spear, or the tail for a rope, and so forth.</p>
<p>I want to see the whole elephant! Don’t you?</p>
</aside>
</section><section class="slide level2">

<p>
<a href="https://commons.wikimedia.org/wiki/File:Pieter_Bruegel_the_Elder_-_The_Tower_of_Babel_(Vienna)_-_Google_Art_Project.jpg#/media/File:Pieter_Bruegel_the_Elder_-_The_Tower_of_Babel_(Vienna)_-_Google_Art_Project.jpg"><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/5/50/Pieter_Bruegel_the_Elder_-_The_Tower_of_Babel_%28Vienna%29_-_Google_Art_Project.jpg/1200px-Pieter_Bruegel_the_Elder_-_The_Tower_of_Babel_%28Vienna%29_-_Google_Art_Project.jpg" alt="Pieter Bruegel the Elder - The Tower of Babel (Vienna) - Google Art Project.jpg" height=500px></a>
</p>
<!-- And like the builders of the Tower of Babel after suffering God's wrath, we often struggle to communicate with one another about essential ideas. -->
<aside class="notes">
<p>This painting of the Tower of Babel should remind all of us often we’re like the builders after suffering God’s wrath: Too often we struggle to communicate with one another about essential concepts and ideas from our distinct subfields.</p>
<p>For example, William James may have said that ‘everyone knows what attention is’, but I’m not sure we agree.</p>
</aside>
</section><section class="slide level2">

<p><img src="img/nested-causality-labels.png" height=600px/></p>
<!-- Perhaps less widely appreciated, the phenomena we study have a nested structure. -->
<aside class="notes">
<p>Relatedly, but perhaps less widely appreciated, the phenomena we study have a complex nested structure.</p>
<p>I designed this logo for my lab group to remind me of it.</p>
<p>The science of the mind and behavior collects and integrates evidence from at least four logically separable but mutually embedded realms.</p>
</aside>
</section><section class="slide level2">

<ul>
<li>Body (<span class="math inline">\(B\)</span>) within world (<span class="math inline">\(W\)</span>)</li>
<li>Nervous system (<span class="math inline">\(N\)</span>) within body (<span class="math inline">\(B\)</span>)</li>
<li>Mind (<span class="math inline">\(M\)</span>) within nervous system (<span class="math inline">\(N\)</span>)</li>
</ul>
<aside class="notes">
<p>Our bodies are embedded in a world. Our nervous systems with our bodies. And our mind within the nervous system.</p>
</aside>
</section><section class="slide level2">

<p><span class="math inline">\(\dot{M} = f(M,N)\)</span></p>
<p><span class="math inline">\(\dot{N} = f(N,B)\)</span></p>
<p><span class="math inline">\(\dot{B} = f(B,N,W)\)</span></p>
<p><span class="math inline">\(\dot{W} = f(W,B)\)</span></p>
<aside class="notes">
<p>And using the mathematical language of dynamical systems, we can say that these realms are mutually coupled to one another: Changes in the mind are a function of mental and nervous system states, and so forth…</p>
<p>And make no mistake: The mind, brain, and body are non-linear dynamical systems, whether or not we study them that way.</p>
<p>Dynamical systems involve rule-based changes in state variables.</p>
</aside>
</section><section id="measure" class="slide level2">
<h2>Measure</h2>
<!-- The good news is that we have tools for measuring... -->
<aside class="notes">
<p>We have a growing box of tools for measuring many of them.</p>
</aside>
</section><section class="slide level2">

<ul>
<li><span class="math inline">\(W\)</span>, <span class="math inline">\(B\)</span>, <span class="math inline">\(N\)</span> more or less <strong>directly</strong></li>
</ul>
<!-- States of the world, the body, and the nervous system more or less directly, across the multiple spatial and temporal scales of the relevant phenomena. -->
<aside class="notes">
<p>States of the world, the body, and the nervous system can be measured more or less directly…</p>
</aside>
</section><section class="slide level2">

<p><a href=""> <img src="https://media.nature.com/lw926/nature-assets/neuro/journal/v17/n11/images/nn.3839-F1.jpg" height=500px/> </a></p>
<p><small> <a href="http://doi.org/10.1038/nn.3839">Sejnowski, Churchland, &amp; Movshon, 2014</a> </small></p>
<aside class="notes">
<p>…across multiple spatial &amp; temporal scales. This figure from Sejnowski et al. shows how the neuroscientist’s toolkit has expanded substantially over the last several decades.</p>
<p>I believe that JSMF support has contributed to this growth.</p>
</aside>
</section><section class="slide level2">

<ul>
<li>Measure mental states <span class="math inline">\(M\)</span> <strong>indirectly</strong></li>
<li>Via <span class="math inline">\(N\)</span>, <span class="math inline">\(B\)</span>, <span class="math inline">\(W\)</span> (+ prior beliefs/knowledge)</li>
</ul>
<!-- But unfortunately, while often the star of the psychological show, we can only measure mental states indirectly via the nervous system, or changes in body state or behavior, and informed by prior beliefs and knowledge about those states. -->
<aside class="notes">
<p>But unfortunately, while often the star of the psychological show, we can only measure mental states indirectly via the nervous system, or changes in body state or behavior, and informed by prior beliefs and knowledge about those states.</p>
<p>I think these differences in measurement have consequences for inference we have yet to confront fully.</p>
<p>Beyond challenges in measurement, we may not appreciate the structure of the theoretical frameworks that dominate our scientific discourse.</p>
<p>I’ve recently become interested in some of the intellectual ancestors to cognitive science that we seem to have abandoned along the way: cybernetics and control theory are among them.</p>
</aside>
</section><section id="linearopen-loop-theoretical-frameworks-dominate" class="slide level2">
<h2>Linear/open-loop theoretical frameworks dominate</h2>
<!-- We have a long and rich intellectual history that rests on a linear/open loop conceptualization. -->
<aside class="notes">
<p>In the language of these fields, linear/open-loop theoretical frameworks dominate psychological science.</p>
</aside>
</section><section class="slide level2">

<p><img src="https://www.biography.com/.image/ar_1:1%2Cc_fill%2Ccs_srgb%2Cg_face%2Cq_auto:good%2Cw_300/MTE5NTU2MzE2MzcxNTg0NTIz/bf-skinner-9485671-1-402.jpg" height=500px/></p>
<p>B.F. Skinner</p>
<aside class="notes">
<p>Consider the S-R psychology of the behaviorists, best epitomized by B.F. Skinner.</p>
</aside>
</section><section class="slide level2">

<p><span class="math inline">\(Stimulus (S) \rightarrow Response (R)\)</span></p>
<p><img src="index_files/figure-revealjs/unnamed-chunk-1-1.png" width="768" /></p>
<aside class="notes">
<p>Behaviorism attempted to show how all observable behavior could be determined by understanding the links between stimuli and responses.</p>
</aside>
</section><section class="slide level2">

<p><img src="https://theintercept.imgix.net/wp-uploads/sites/1/2018/09/American-Dissident-Noam-Chomsky-on-the-State-of-the-Empire-1537928785.jpg?auto=compress%2Cformat&q=90&fit=crop&w=1440&h=720"/></p>
<p>Noam Chomsky</p>
<aside class="notes">
<p>Or the cognitive critique of behaviorism articulated most effectively by Noam Chomsky.</p>
</aside>
</section><section class="slide level2">

<p><span class="math inline">\(Stimulus (S) \rightarrow Cognition (C) \rightarrow Response (R)\)</span></p>
<p><img src="index_files/figure-revealjs/unnamed-chunk-2-1.png" width="768" /></p>
<aside class="notes">
<p>Here significant, essential processing (cognition or computation) intervene between stimulus and response.</p>
</aside>
</section><section class="slide level2">

<!-- Michael Gazzaniga -->
<p><img src="https://www.psych.ucsb.edu/sites/www.psych.ucsb.edu/files/styles/portrait-full/public/images/faculty/gazzaniga_02.jpg?itok=hkXryDw_" height=500px/></p>
<aside class="notes">
<p>Or the marriage of neuroscience with cognitive science advanced by Michael Gazzaniga…</p>
</aside>
</section><section class="slide level2">

<p><span class="math inline">\(S \rightarrow N \leftrightarrow C \rightarrow R\)</span></p>
<p><img src="index_files/figure-revealjs/unnamed-chunk-3-1.png" width="768" /></p>
<aside class="notes">
<p>that brings to bear evidence about the computing hardware to understanding the operation of the mind’s software.</p>
<p>Make no mistake, I view this progression of ideas as advancing our understanding of the mind and brain.</p>
</aside>
</section><section id="closed-loop-causal-chains-better-reflect-the-underlying-reality" class="slide level2">
<h2><em>Closed-loop</em> causal chains better reflect the underlying reality</h2>
<!-- When in fact, closed-loop causal chains better reflect the underlying reality of the embedded and coupled systems we care about understanding. -->
<aside class="notes">
<p>But I also think that the underlying reality is more complex than this, and that non-linear, closed-loop, causal chains better reflect what cognitive science is really about.</p>
</aside>
</section><section class="slide level2">

<p><img src="index_files/figure-revealjs/unnamed-chunk-4-1.png" width="768" /></p>
<aside class="notes">
<p>The reality is that responses affect the world, responses and world states evoke stimuli, stimuli affects cognition, cognition affects responses, and the cycle repeats.</p>
<p>Non-linear, closed-loop dynamical systems like this require broader and denser data about all of the realms in order to reveal the underlying processes. Data that can be difficult or expensive to collect.</p>
<p>But even in situations when the data are available, when all of these states are well-known, our current methods have some striking limitations.</p>
</aside>
</section><section class="slide level2">

<p><img src="img/jonas-kording-2017.jpg" width=1000px/></p>
<p><small> <a href="https://doi.org/10.1371/journal.pcbi.1005268">Jonas &amp; Kording 2017</a> </small></p>
<!-- Jonas and Kording used conventional neuroscience techniques to simulate 'recording' from a microprocessor that was engaged in the inputs and outputs of a well-known video game. -->
<aside class="notes">
<p>A recent paper by Jonas and Kording illustrates this point. These authors used conventional neuroscience techniques – studying the connection pattern, observing the effects of damage on performance, responses of individual components to simulate ‘recording’ from a microprocessor that was engaged in the inputs and outputs of several well-known video games. So, in effect, they already ‘knew’ the answers they were looking for.</p>
<p>What did they find?</p>
</aside>
</section><section class="slide level2">

<blockquote>
<p>“<em>We show that [classic analytic neuroscience] approaches reveal interesting structure in the data…</em>”</p>
</blockquote>
<p><small> <a href="https://doi.org/10.1371/journal.pcbi.1005268">Jonas &amp; Kording 2017</a> </small></p>
</section><section class="slide level2">

<blockquote>
<p>“<em>…but do not meaningfully describe the hierarchy of information processing in the microprocessor.</em>”</p>
</blockquote>
<p><small> <a href="https://doi.org/10.1371/journal.pcbi.1005268">Jonas &amp; Kording 2017</a> </small></p>
</section><section class="slide level2">

<blockquote>
<p>“<em>This suggests current analytic approaches in neuroscience may fall short of producing meaningful understanding of neural systems, regardless of the amount of data.</em>”</p>
</blockquote>
<p><small> <a href="https://doi.org/10.1371/journal.pcbi.1005268">Jonas &amp; Kording 2017</a> </small></p>
<!-- So, while there are many questions in cognitive science and neuroscience where more data are essential, bigger data aren't enough. -->
<!-- Moreover, there are reasons to think we may need to broaden our approach. -->
<aside class="notes">
<p>So, while there are many questions in cognitive science and neuroscience where more data are essential, bigger data aren’t enough.</p>
<p>Moreover, there are reasons to think we may need to broaden our approach to information processing.</p>
</aside>
</section><section class="slide level2">

<iframe src="https://www.theatlantic.com/technology/archive/2015/09/not-even-the-people-who-write-algorithms-really-know-how-they-work/406099/" height="600" width="1000">
</iframe>
<aside class="notes">
<p>The Turing machine as a universal computational device is the dominant framework in computer science, and most cognitive scientists think (explicitly or not) that the mind is some sort of computational device.</p>
<p>Central to this way of thinking is the goal of cognitive science is to reveal the algorithms or recipe for evaluating and transforming data.</p>
<p>We don’t have to look very far to see how powerful and widespread algorithms have become in our day-to-day life.</p>
</aside>
</section><section class="slide level2">

<p>
<p><a href="https://commons.wikimedia.org/wiki/File:Maquina_vapor_Watt_ETSIIM.jpg#/media/File:Maquina_vapor_Watt_ETSIIM.jpg"><img src="https://upload.wikimedia.org/wikipedia/commons/9/9e/Maquina_vapor_Watt_ETSIIM.jpg" alt="Maquina vapor Watt ETSIIM.jpg" height=600px></a></p>
<small> <br>By Nicolás Pérez, <a href="http://creativecommons.org/licenses/by-sa/3.0/" title="Creative Commons Attribution-Share Alike 3.0">CC BY-SA 3.0</a>, <a href="https://commons.wikimedia.org/w/index.php?curid=195711">Link</a>
</p>
<p></small></p>
<aside class="notes">
<p>But algorithms aren’t the only useful ways to transform information.</p>
<p>This is the steam engine designed by James Watt in the late 1700s. It helped launch the industrial age.</p>
</aside>
</section><section class="slide level2">

<ul>
<li>How to regulate the speed of a Watt-style steam engine?</li>
</ul>
<aside class="notes">
<p>And like most powerful and useful machines, it has to be controlled to be useful. Beyond turning it on and off, the most important control is speed. How to keep the speed constant?</p>
</aside>
</section><section class="slide level2">

<pre><code>1. Measure the speed of the flywheel.
2. Compare the actual speed against the desired speed.
3. If there is no discrepancy, return to step 1. Otherwise,
    a. measure the current steam pressure;
    b. calculate the desired alteration in steam pressure;
    c. calculate the necessary throttle valve adjustment.
4. Make the throttle valve adjustment.
5. Return to step 1. </code></pre>
<aside class="notes">
<p>To a 21st century audience steeped in algorithmic thinking and surrounded by computational devices, the answer is obvious: Measure the speed, compare it to some desired value, if it differs, adjust the steam valve up or downward.</p>
<p>This is a negative feedback loop of the sort we’re familiar with in various contexts, from thermostats to cruise control in our cars.</p>
<p>Note that the algorithm presumes that there are variables we can measure – like speed, and calculations we can quickly and accurately.</p>
</aside>
</section><section class="slide level2">

<p>
<a href="https://commons.wikimedia.org/wiki/File:Centrifugal_governor.png#/media/File:Centrifugal_governor.png"><img src="https://upload.wikimedia.org/wikipedia/commons/1/1e/Centrifugal_governor.png" alt="Centrifugal governor.png" height=600px></a>
</p>
<!-- The real world solution Watt devised was a mechanical one. It took advantage of the interactions of mechanical elements, rotational and gravitational forces. -->
<aside class="notes">
<p>The real world solution Watt devised was mechanical and of a completely different form. Cheap sensors hadn’t been invented yet. All calculation was done by humans, not machines. Watt’s solution took advantage of the interactions of mechanical elements, rotational and gravitational forces.</p>
</aside>
</section><section id="algorithms-vs.dynamics-van-gelder-1995" class="slide level2">
<h2>Algorithms vs. Dynamics (<a href="http://dx.doi.org/10.2307/2941061">Van Gelder, 1995</a>)</h2>
<!-- I give credit to Tim Van Gelder for pointing out that a strictly information processing/computational approach pushes us to seek out algorithms when systems that exploit intrinsic dynamics of the materials might more useful. -->
<aside class="notes">
<p>I thank Tim Van Gelder for persuasively arguing that a strictly information processing/computational approach pushes us to seek out algorithms when systems that exploit intrinsic dynamics of the materials might more useful or appropriate.</p>
</aside>
</section><section class="slide level2">

<ul>
<li>“If all you have is a hammer, everything looks like a nail.” (Maslow)</li>
<li>How much do we <em>really</em> understand about biological computing?</li>
</ul>
<aside class="notes">
<p>The implication is that we may see computational devices everywhere because they are ubiquitous in the environments we have created.</p>
<p>But does this necessarily mean that biological entities work this way or in all cases? How much do we really understand about how biological entities compute?</p>
</aside>
</section><section id="biological-computing" class="slide level2">
<h2><em>Biological</em> computing</h2>
</section><section class="slide level2">

<ul>
<li>Constrained by space, time, energy</li>
</ul>
</section><section class="slide level2">

<p><img src="https://images.newscientist.com/wp-content/uploads/2017/05/23120156/rexfeatures_8828108ac1-800x533.jpg" height=500px/></p>
<p>25 W vs. ?? MW</p>
<!-- Alpha Go vs. Ke Jie -->
<aside class="notes">
<p>This photo shows Google’s AI system, AlphaGo in the midst of defeating the World Champion Go player. Considering that Go was thought far too difficult a game for computers to master, it’s indeed an achievement.</p>
<p>But the human player’s brain was using about 25 W. I don’t know that Google has revealed AlphaGo’s power consumption in doing the same task, but it was probably in the megawatts.</p>
<p>So we’re a long way from developing computational systems that are as energy efficient as brains.</p>
</aside>
</section><section class="slide level2">

<!-- Biological computing... -->
<ul>
<li>Computes with chemistry (neurotransmitters, hormones) when possible</li>
<li>With ‘wires’ (axons &amp; dendrites) when necessary</li>
</ul>
<aside class="notes">
<p>One reason for this may be that biological computing seems to involve chemistry whenever possible, and wires only when necessary.</p>
</aside>
</section><section class="slide level2">

<p><img src="https://images.gr-assets.com/books/1466902982l/23582015.jpg" height=600px/></p>
<aside class="notes">
<p>Peter Sterling and Simon Laughlin discuss the implications of this in their book Neural Computing.</p>
<p>I think it’s safe to say that we don’t yet appreciate the implications of this sort of hybrid computing architecture.</p>
</aside>
<!-- Sterling and Laughlin -->
</section><section id="biological-computing-1" class="slide level2">
<h2><em>Biological</em> computing</h2>
<aside class="notes">
<p>There are other important facets of biological computing.</p>
</aside>
</section><section class="slide level2">

<ul>
<li>Engages in real-time behaviors with existential consequences (e.g., ingestion, defense, reproduction, locomotion, pursuit)</li>
<li>Operates effectively in complex, dynamic environments</li>
<li>Operates in single cells to aggregates of quadrillions…</li>
</ul>
<aside class="notes">
<p>It [READ slide]</p>
</aside>
</section><section class="slide level2">

<iframe width="800" height="600" src="https://www.youtube.com/embed/9nxoSRasq2Q" frameborder="0" allow="accelerometer; data-autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen>
</iframe>
<aside class="notes">
<p>This video shows a species of algae, <em>Euglena</em>, locomoting through the environment with the help of a whip-like flagellum.</p>
<p>If we count sensation, locomotion, decision-making, adaptation as part of the cognitive apparatus, then even single celled organisms seem to carry out these operations in some form.</p>
</aside>
<!-- Video of Euglena in locomotion -->
<!-- to live is to move, sense, compute, adapt... -->
<!-- ## Biological computing -->
<!-- --- -->
<!-- - Separates neural 'streams' for $S \leftrightarrow C \leftrightarrow A$ -->
<!-- --- -->
<!-- <div class="centered"> -->
<!-- <img src="https://raw.githubusercontent.com/psu-psychology/psy-511-scan-fdns-2017/master/lectures/img/swanson-2005-fig-1.jpg" height=600px/> -->
<!-- <small> -->
<!-- [Swanson 2005](http://dx.doi.org/10.1002/cne.20733) -->
<!-- </small> -->
<!-- </div> -->
<!-- ## Bigger, denser, more diverse data will help, but -->
<!-- ## Big data (-omics) initiatives in the biological sciences... -->
<!-- --- -->
<!-- - [Genome](https://www.genome.gov/12011238/an-overview-of-the-human-genome-project/) -->
<!-- - [Proteome](https://hupo.org/human-proteome-project) -->
<!-- - [Metabolome](http://www.hmdb.ca/) -->
<!-- - [Connectome](http://www.humanconnectomeproject.org/) -->
</section><section id="to-live-is-to-move-sense-compute-adapt" class="slide level2">
<h2>To live is to move, sense, compute, adapt…</h2>
<aside class="notes">
<p>Indeed, we can rightly say that moving, sensing, computing, adapting are fundamental properties of life.</p>
<p>Now, I’m not suggesting that biological computing in single-celled organisms is identical to that of multicellular organisms or that these processes should be called ‘cognition’. But I am saying that we might gain some insight into human cognition by asking what parts of this elephant we’re ignoring.</p>
</aside>
</section><section id="big-data--omics-approaches-to-other-questions-in-biomedicine-largely-overlook-behavior" class="slide level2">
<h2>Big data (-omics) approaches to other questions in biomedicine largely overlook <em>behavior</em></h2>
<aside class="notes">
<p>For example, other areas of biomedicine have taken ‘big data’ approaches to revealing the structure at different levels of spatial and temporal resoulution.</p>
<p>Of course I refer to the genome, proteome, metabolome, and connectome projects.</p>
<p>Curiously, these approaches largely overlook one of the principal outputs of all of this machinery: <em>behavior</em>.</p>
</aside>
</section><section class="slide level2">

<p><a href="https://doi.org/10.1016/j.neuron.2016.12.041"> <img src="img/krakauer.jpg" height=600px/> </a></p>
<!-- Krakauer paper title -->
<aside class="notes">
<p>The oversight is slowly gaining recognition in neuroscience, as indicated by this recent paper by Krakauer and colleagues.</p>
</aside>
</section><section class="slide level2">

<div class="centered">
<p><img src="https://ars.els-cdn.com/content/image/1-s2.0-S0896627316310406-gr1.jpg" height=600px/></p>
<p><small> <a href="https://doi.org/10.1016/j.neuron.2016.12.041">Krakauer et al. 2017</a> </small></p>
</div>
<aside class="notes">
<p>Krakauer and colleagues question whether the behaviors we study are truly representative, whether there is a one-to-one relationship between brain systems and those behaviors, and so on.</p>
</aside>
</section><section class="slide level2">

<blockquote>
<p>“<em>Behavior is the linchpin of the most vexing problems in public health…</em>”</p>
</blockquote>
<p><small> <a href="https://www.rick-gilmore.com/post/behavior-is-the-linchpin/">Gilmore, Adolph, &amp; Tamis-LeMonda, 2019</a> </small></p>
<aside class="notes">
<p>My colleagues and I have argued that behavior is the linchpin of the most vexing problems in public health.</p>
</aside>
</section><section class="slide level2">

<blockquote>
<p>“<em>Behavior contributes to the progression or prevention of disease, defines a disorder or marks recovery, and provides mechanisms for therapeutic intervention.</em>”</p>
</blockquote>
<p><small> <a href="https://www.rick-gilmore.com/post/behavior-is-the-linchpin/">Gilmore, Adolph, &amp; Tamis-LeMonda, 2019</a> </small></p>
<aside class="notes">
<p>That behavior contributes to the progression or prevention of disease, defines a disorder or marks recovery, and provides mechanisms for therapeutic intervention.</p>
</aside>
</section><section class="slide level2">

<blockquote>
<p>“<em>…a better understanding of behavior is fundamental to achieving positive health outcomes, from prenatal development throughout adulthood.</em>”</p>
</blockquote>
<p><small> <a href="https://www.rick-gilmore.com/post/behavior-is-the-linchpin/">Gilmore, Adolph, &amp; Tamis-LeMonda, 2019</a> </small></p>
<aside class="notes">
<p>And that a better understanding of behavior is fundamental to achieving positive health outcomes, from prenatal development throughout adulthood.</p>
<p>I’d extend these claims to the principal task of understanding human cognition.</p>
</aside>
</section><section class="slide level2">

<p><img src="https://researchforevidence.fhi360.org/wp-content/uploads/2017/07/mastro-1200x800-768x512.png" height=600px/></p>
<aside class="notes">
<p>So psychology and allied fields are harder than physics for many reasons.</p>
<p>But there is an additional challenge that all sciences face: The challenge of producing reliable, robust, generalizable findings.</p>
<p>Richard Harris’ book, Rigor Mortis, exposes some shocking problems with reproducibility in biomedical research, and I urge you to read it.</p>
</aside>
</section><section id="is-there-a-reproducibility-crisis-in-science" class="slide level2">
<h2>Is there a reproducibility crisis in science?</h2>
<aside class="notes">
<p>But let’s start with a question: Is there a reproducibility crisis in science?</p>
<p>Nature asked scientists across fields this question in 2016.</p>
<p>Let’s focus on psychological science.</p>
</aside>
</section><section class="slide level2">

<ul>
<li>Yes, a significant crisis</li>
<li>Yes, a slight crisis</li>
<li>No crisis</li>
<li>Don’t know</li>
</ul>
<aside class="notes">
<p>So, how many of you think there is a significant crisis in psychological science? A slight crisis? No crisis? Don’t know.</p>
</aside>
</section><section class="slide level2">

<div class="centered">
<p><img src="http://www.nature.com/polopoly_fs/7.36716.1469695923!/image/reproducibility-graphic-online1.jpeg_gen/derivatives/landscape_630/reproducibility-graphic-online1.jpeg" height=600px> </br> <small> <a href="http://doi.org/10.1038/533452a">Baker, 2016</a> </small></p>
</div>
<aside class="notes">
<p>These are the results.</p>
</aside>
</section><section id="have-you-failed-to-reproduce-an-experiment-from-your-lab-or-someone-elses" class="slide level2">
<h2>Have you failed to reproduce an experiment from your lab or someone else’s?</h2>
<aside class="notes">
<p>Nature asked a second question you can think about yourself.</p>
<p>I think the results are especially interesting.</p>
</aside>
</section><section class="slide level2">

<div class="centered">
<p><img src="http://www.nature.com/polopoly_fs/7.36718.1464174471!/image/reproducibility-graphic-online3.jpg_gen/derivatives/landscape_630/reproducibility-graphic-online3.jpg"" width=700px> </br> <small> <a href="http://doi.org/10.1038/533452a">Baker, 2016</a> </small></p>
</div>
<aside class="notes">
<p>Look at the fields where the highest levels of failures to replicate are reported: chemistry, biology, physics &amp; engineering, earth and mineral sciences. The so-called ‘hard’ sciences.</p>
<p>I’m not sure, but I think psychology and the social sciences fall into ‘other’. See, we’re not doing so badly!</p>
</aside>
</section><section class="slide level2">

<div class="centered">
<p><a href="http://www.nature.com/polopoly_fs/7.36719.1464174488!/image/reproducibility-graphic-online4.jpg_gen/derivatives/landscape_630/reproducibility-graphic-online4.jpg"> <img src="http://www.nature.com/polopoly_fs/7.36719.1464174488!/image/reproducibility-graphic-online4.jpg_gen/derivatives/landscape_630/reproducibility-graphic-online4.jpg" width=800px> </a></p>
<p><small><a href="http://doi.org/10.1038/533452a">Baker 2016</a></small></p>
</div>
<!-- Factors contributing to irreproducible research -->
<aside class="notes">
<p>We won’t dwell on the factors that respondents said contribute to these problems, but I think they are by now familiar.</p>
</aside>
</section><section class="slide level2">

<div class="centered">
<p><a href="http://www.nature.com/articles/s41562-016-0021/figures/1"> <img src="https://media.nature.com/lw926/nature-assets/nathumbehav/2017/s41562-016-0021/images_hires/s41562-016-0021-f1.jpg" height=500px> </a></p>
<p><small><a href="http://doi.org/10.1038/s41562-016-0021">Munafo et al. 2017</a></small></p>
</div>
<aside class="notes">
<p>And I’m greatly encouraged by the attention and energy psychologists are giving to how to improve research methodology and inference.</p>
</aside>
</section><section class="slide level2">

<p><img src="https://www.rd.com/wp-content/uploads/2017/02/01-How-Bad-is-it-to-Share-a-Toothbrush-159311405-ABykov-760x506.jpg" height=600px/></p>
<aside class="notes">
<p>One area where I think we could spend a bit more energy concerns the role of theory, and for this, I thank George Mischel for giving the problem a clever name: the toothbrush problem.</p>
</aside>
</section><section class="slide level2">

<blockquote>
<p>“<em>…psychologists tend to treat other peoples’ theories like toothbrushes; no self-respecting individual wants to use anyone else’s.</em>”</p>
</blockquote>
<p><small><a href="https://www.psychologicalscience.org/observer/becoming-a-cumulative-science">Mischel, 2009</a></small></p>
</section><section class="slide level2">

<blockquote>
<p>“<em>The toothbrush culture undermines the building of a genuinely cumulative science, encouraging more parallel play and solo game playing, rather than building on each other’s directly relevant best work.</em>”</p>
</blockquote>
<p><small><a href="https://www.psychologicalscience.org/observer/becoming-a-cumulative-science">Mischel, 2009</a></small></p>
<aside class="notes">
<p>Do we want to build a ‘genuinely cumulative science’?</p>
<p>I do, and I think you do, too.</p>
<p>So what do we need to do?</p>
<p>[RIGHT]</p>
</aside>
</section></section>
<section><section id="making-cognitive-science-even-better" class="titleslide slide level1"><h1>Making cognitive science even better</h1></section><section id="support-research-that" class="slide level2">
<h2>Support research that</h2>
<aside class="notes">
<p>I suggest that sponsors like JSMF should support research that…</p>
</aside>
</section><section class="slide level2">

<ul>
<li>studies <em>behavior(s)</em></li>
<li>not just (difficult-to-measure-directly) internal states</li>
</ul>
</section><section class="slide level2">

<p><img src="img/powers-5.1.png" height=600px/></p>
<p><small><a href="https://www.amazon.com/Behavior-Perception-William-T-Powers/dp/0964712172">Powers 1973</a> </small></p>
<aside class="notes">
<p>Bill Powers work on perceptual control theory seems to have left little mark on psychology, but this figure from his 1973 book I find instructive.</p>
<p>It shows how one might decompose a simple object tracking task into a series of perception/computation/action loops.</p>
<p>We could and should have rich descriptions of and theories about behaviors.</p>
</aside>
</section><section class="slide level2">

<ul>
<li>samples densely (and/or broadly) in time &amp; space</li>
<li>creates meaningful linkages across levels of analysis</li>
</ul>
<aside class="notes">
<p>I also recommend that sponsors support research that samples densely or broadly in time &amp; space and strives to achieve meaningful linkages across levels of analysis.</p>
</aside>
</section><section class="slide level2">

<div class="centered">
<p><img src="http://3.bp.blogspot.com/-3e_SbLI1Kbc/UkH085O8q5I/AAAAAAAACw4/lAZ_AJdzGss/s1600/bronfenbrenner.jpeg" height=500px></p>
</div>
<aside class="notes">
<p>As this figure from Bronfenbrenner depicts, psychologists, especially those with training in development have long understood that a satisfying understanding of human behavior requires understanding influences within the individual and outside her.</p>
</aside>
</section><section class="slide level2">

<div class="centered">
<p><img src="https://www.researchgate.net/profile/Carlo_Miniussi/publication/269877702/figure/fig2/AS:269128527249411@1441176649721/Hierarchical-modular-organisation-of-the-human-connectome-a-Hubs-regions-with-a.png" height=500px></p>
</div>
<aside class="notes">
<p>In neuroscience, the tools of network theory have come to play important roles in inference.</p>
<p>And network theory is a tool that will help cognitive scientists characterize the networks of factors that influence human computation.</p>
</aside>
</section><section class="slide level2">

<ul>
<li>“Responses” include behaviors</li>
<li>AND autonomic/endocrine activity</li>
<li>AND…</li>
</ul>
<aside class="notes">
<p>I also suggest that the range of behaviors or responses studied be broadened to include not only changes in or the active maintenance of body configurations but also heart rate, respiration, and other autonomic ‘behaviors’ and endocrine/hormonal activity.</p>
</aside>
</section><section class="slide level2">

<p><img src="https://i.ytimg.com/vi/kAy-03hIfck/maxresdefault.jpg" height=500px/></p>
<!-- Bart Simpson homeostasis -->
<aside class="notes">
<p>This Simpson’s cartoon depicts the classic model system for studying homeostasis, temperature regulation.</p>
</aside>
</section><section class="slide level2">

<p><img src="https://www.teachengineering.org/content/nyu_/activities/nyu_homeostasis/nyu_homeostasis_activity1_image1.jpg" height=500px/></p>
<!-- Multiple loops for thermoregulation -->
<aside class="notes">
<p>Thermoregulation is a useful system for depicting negative feedback systems and multiple perceptual/action systems.</p>
<p>But it’s likely that many other behavioral systems can be understood in similar terms. Indeed, one insight from control theory and cybernetics is that if some variable is stable across time or space, it’s subject to some form of control.</p>
</aside>
</section><section id="support-research-that-1" class="slide level2">
<h2>Support research that</h2>
<aside class="notes">
<p>I suggest that we augment support for research that…</p>
</aside>
</section><section class="slide level2">

<ul>
<li>attempts to close causal loops</li>
<li>via specific algorithms and/or dynamical processes</li>
</ul>
</section><section class="slide level2">

<ul>
<li>informed by rich theories of task performance (inputs, controlled variables, outputs)</li>
<li>resists “premature simplification”</li>
</ul>
<aside class="notes">
<p>What’s premature simplification?</p>
</aside>
</section><section class="slide level2">

<p><img src="https://i0.wp.com/flowingdata.com/wp-content/uploads/2017/05/DataDino-600x455.gif?fit=600%2C455&ssl=1"></p>
<p><small> <a href="https://www.autodeskresearch.com/publications/samestats">Matejka &amp; Fitzmaurice</a> </small></p>
<aside class="notes">
<p>These data (the Datasaurus dozen) are a version of Anscome’s Quartet known to statistics for a long time. All of the distributions have the same means in X and Y, the same standard deviations, and the same correlations. If we didn’t visualize the data, and took as a given the simplification provided by the summary statistics, we’d miss important details.</p>
<p>Dimension reduction or simplification is essential in science, but only when it adds to our understanding and doesn’t discard something essential.</p>
<p>The challenge is knowing when it’s safe to simplify and when it’s not.</p>
</aside>
</section><section class="slide level2">

<p><img src="img/powers-6.1.png" height=800px/></p>
<p><small><a href="https://www.amazon.com/Behavior-Perception-William-T-Powers/dp/0964712172">Powers 1973</a> </small></p>
<aside class="notes">
<p>This figure from Bill Powers again shows a later, more complex version of the same visual object tracking task. Here the more complicated model explains more aspects of behavior.</p>
<p>I suggest that cognitive science can and should probably complicate before we simplify.</p>
</aside>
</section><section class="slide level2">

<ul>
<li>demonstrates a meaningful commitment to producing rigorous, reproducible, &amp; robust findings</li>
</ul>
<aside class="notes">
<p>I also recommend providing support for research that demonstrates a meaningful commitment to producing rigorous, reproducible, &amp; robust findings.</p>
<p>That is, findings we can bank on.</p>
</aside>
</section><section class="slide level2">

<p><img src="https://cdn-images-1.medium.com/max/638/1*SLh1zk2qoV_ud3nlwF4R8Q.png" height=600px/></p>
<aside class="notes">
<p>This recent book by Deborah Mayo argues that whatever statistical framework we adopt, the common goal ought to be to rigorously test scientific claims with only the strongest surviving the tests.</p>
</aside>
</section><section id="support-research-that-2" class="slide level2">
<h2>Support research that</h2>
<aside class="notes">
<p>In that spirit, I recommend that sponsors support research…</p>
</aside>
</section><section class="slide level2">

<ul>
<li>collects &amp; shares video as data &amp; documentation</li>
</ul>
<aside class="notes">
<p>that collects and shares video as data and documentation.</p>
</aside>
</section><section id="why-video" class="slide level2">
<h2>Why video?</h2>
<aside class="notes">
<p>Why single-out video?</p>
</aside>
</section><section class="slide level2">

<iframe src="https://www.apa.org/science/about/psa/2017/10/video-data" height="600px" width="800px">
</iframe>
<aside class="notes">
<p>For starters, my colleagues and I have argued that the more widespread use of video for both purposes will improve psychological science.</p>
</aside>
</section><section id="video" class="slide level2">
<h2>Video…</h2>
<ul>
<li>Captures (&amp; preserves) behavior</li>
<li>Shows (&amp; helps tell…)</li>
<li>Expands the scope of inquiry</li>
<li>Provides unequaled opportunities for reuse</li>
</ul>
</section><section class="slide level2">

<video height="600" data-autoplay>
<source src="https://nyu.databrary.org/slot/27087/0,79000/asset/119877/download?inline=true" type="video/mp4"> Your browser does not support the video tag.
</video>
<aside class="notes">
<p>We’re putting these claims to a very public test through the Play &amp; Learning Across a Year (PLAY) project.</p>
<p>PLAY is collecting video recordings of mothers and infants engaged in natural activity in the home.</p>
<p>Human observers will add time-locked annotations of speech, language, and gesture, locomotion and physical activity, object interaction, and emotion.</p>
</aside>
</section><section class="slide level2">

<p><span class="math inline">\(n=900\)</span> 12-, 18-, 24-mo-olds; <span class="math inline">\(n=30\)</span> sites </br></br> demographics, health, vocabulary, media use, &amp; temperament </br></br> openly shared with the research community </br></br> <a href="https://www.play-project.org">play-project.org</a></p>
<aside class="notes">
<p>The coded videos plus parent-report information will be openly shared with the research community via Databrary.</p>
</aside>
</section><section id="support-research-that-3" class="slide level2">
<h2>Support research that</h2>
<ul>
<li>Shares procedures, materials, code, &amp; data openly (but securely)</li>
</ul>
<aside class="notes">
<p>To build on the substantial progress psychological science is making in terms of reproducibility, I recommend supporting research that shares procedures, materials, code, &amp; data openly (but securely).</p>
</aside>
</section><section class="slide level2">

<iframe src="https://play-behaviorome.github.io/PLAY-project.org/" height="600" width="800">
</iframe>
<aside class="notes">
<p>For PLAY, that means a completely open protocol, including coding definitions, item-level survey information, and so on.</p>
</aside>
</section><section class="slide level2">

<ul>
<li>Makes sharing scripted, fully reproducible workflows easy</li>
</ul>
<aside class="notes">
<p>Sponsors should also support research that makes it easy for others to validate findings by creating scripted, fully reproducible workflows.</p>
</aside>
</section><section class="slide level2">

<iframe src="https://doi.org/10.17910/B7CC74" height="600" width="800">
</iframe>
<p><small> <a href="https://doi.org/10.17910/B7CC74">Tamis-LeMonda 2014</a> </small></p>
<aside class="notes">
<p>Here’s an example, let’s say you want to explore building upon Catherine Tamis-LeMonda’s shared dataset. It’s one of the largest and most diverse.</p>
</aside>
</section><section class="slide level2">

<pre><code>vol_8 &lt;- databraryapi::download_session_csv(vol_id = 8)
vol_8 %&gt;%
  filter(participant.gender %in% c(&#39;Male&#39;, &#39;Female&#39;)) %&gt;%
  ggplot() +
  aes(x = participant.race, fill = participant.race) +
  facet_grid(. ~ participant.gender) +
  geom_bar(stat=&quot;count&quot;) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))</code></pre>
<aside class="notes">
<p>This small fragment of code from the R programming language downloads demographic data from Cathie’s dataset and produces this summary plot.</p>
</aside>
</section><section class="slide level2">

<p><img src="index_files/figure-revealjs/unnamed-chunk-5-1.png" width="768" /></p>
<aside class="notes">
<p>The same code will work on another person’s computer because the data come from Databrary, not from <code>C:\my-research-data\cathie-project</code></p>
</aside>
</section><section class="slide level2">

<p>R package </br> <a href="https://github.com/PLAY-behaviorome/databraryapi" class="uri">https://github.com/PLAY-behaviorome/databraryapi</a></p>
<p>Python package <a href="https://github.com/PLAY-behaviorome/databrarypi" class="uri">https://github.com/PLAY-behaviorome/databrarypi</a></p>
<aside class="notes">
<p>These fully reproducible workflows are made possible by packages in R and Python we are developing that interact securely with the Databrary system.</p>
<p>They even let you excerpt segments of video or audio.</p>
</aside>
</section><section id="support-research-that-4" class="slide level2">
<h2>Support research that</h2>
<aside class="notes">
<p>Finally, I recommend that sponsors support research that</p>
</aside>
</section><section class="slide level2">

<ul>
<li>enables linkages between &amp; across data sets</li>
<li>exploits advances in AI and machine learning</li>
</ul>
</section><section class="slide level2">

<video height="600" data-controls data-autoplay>
<source src="mov/ossmy-openpose.mp4" type="video/mp4"> Your browser does not support the video tag.
</video>
<p><small>Source: Ori Ossmy, NYU</small></p>
<aside class="notes">
<p>The video shows the output of an open source computer vision algorithm called OpenPose run on a video of a child playing in a laboratory setting. These tools promise to accelerate the annotation of video.</p>
<p>Linda Smith and Chen Yu have been pursuing similar efforts in their own work.</p>
</aside>
</section><section class="slide level2">

<p><img src="img/ossmy-gilmore-adolph-2019-fig-02.png" height=600px/></p>
<p><small> <a href="https://doi.org/10.1007/978-3-030-17798-0_14">Ossmy, Gilmore, &amp; Adolph 2019</a> </small></p>
<aside class="notes">
<p>In our work with Ori Ossmy, we’ve shown that computer vision techniques can be 100 times faster than human coders and with similar levels of precision.</p>
<p>The human cost of video annotation is one of the biggest barriers to its widespread use, and so the potential to reduce these substantially is tremedously exciting.</p>
</aside>
</section><section id="if-we-do-these-things" class="slide level2">
<h2>If we do these things…</h2>
<aside class="notes">
<p>In summary, if we do these things…</p>
</aside>
</section><section class="slide level2">

<p><img src="http://cdn2.hubspot.net/hub/134568/file-1208368053-jpg/6-blind-men-hans.jpg" height=600px></p>
<!-- The whole elephant -->
<aside class="notes">
<p>I’m confident that we will move from holding only a tiny bit of the elephant…</p>
</aside>
</section><section class="slide level2">

<div class="centered">
<p><img src="http://static.neatorama.com/images/2012-09/girl-hugging-elephant.jpg" height=600px></p>
<!-- Girl hugging elephant -->
<aside class="notes">
<p>To embracing the full beautiful beast.</p>
</aside>
</section></section>
<section><section id="thank-you" class="titleslide slide level1"><h1>Thank you</h1></section><section class="slide level2">

<video width="800" data-autoplay>
<source src="https://github.com/gilmore-lab/DEVSEC-2018/blob/master/mov/databrary-splash.mp4?raw=true" type="video/mp4">
</video>
<p><small> <a href="mailto:rogilmore@psu.edu">rogilmore@psu.edu</a></br> <a href="https://gilmore-lab.github.io" class="uri">https://gilmore-lab.github.io</a></br> <a href="https://gilmore-lab.github.io/2019-06-03-McDonnell-Fdn/" class="uri">https://gilmore-lab.github.io/2019-06-03-McDonnell-Fdn/</a></br> <a href="https://twitter.com/rogilmore">@rogilmore</a> </small></p>
</section></section>
<section><section id="materials" class="titleslide slide level1"><h1>Materials</h1></section><section class="slide level2">

<p><small> This talk was produced on 2019-06-03 in <a href="http://rstudio.com">RStudio</a> version using R Markdown and the reveal.JS framework. The code and materials used to generate the slides may be found at <a href="https://github.com/gilmore-lab/2019-06-03-McDonnell-Fdn/" class="uri">https://github.com/gilmore-lab/2019-06-03-McDonnell-Fdn/</a>. Information about the R Session that produced the code is as follows:</p>
</section><section class="slide level2">

<pre><code>## R version 3.5.2 (2018-12-20)
## Platform: x86_64-apple-darwin15.6.0 (64-bit)
## Running under: macOS Mojave 10.14.5
## 
## Matrix products: default
## BLAS: /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libBLAS.dylib
## LAPACK: /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRlapack.dylib
## 
## locale:
## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
##  [1] igraph_1.2.2            forcats_0.3.0          
##  [3] stringr_1.4.0           dplyr_0.8.0.1          
##  [5] purrr_0.3.2             readr_1.3.1            
##  [7] tidyr_0.8.2             tibble_2.1.1           
##  [9] ggplot2_3.1.0           tidyverse_1.2.1        
## [11] databraryapi_0.1.6.9001
## 
## loaded via a namespace (and not attached):
##  [1] revealjs_0.9     tidyselect_0.2.5 xfun_0.6         reshape2_1.4.3  
##  [5] haven_2.0.0      lattice_0.20-38  colorspace_1.4-1 generics_0.0.2  
##  [9] htmltools_0.3.6  yaml_2.2.0       rlang_0.3.3      pillar_1.3.1    
## [13] glue_1.3.1       withr_2.1.2      modelr_0.1.2     readxl_1.2.0    
## [17] plyr_1.8.4       munsell_0.5.0    gtable_0.3.0     cellranger_1.1.0
## [21] rvest_0.3.2      codetools_0.2-15 evaluate_0.13    labeling_0.3    
## [25] knitr_1.22       curl_3.3         highr_0.8        broom_0.5.1     
## [29] Rcpp_1.0.1       scales_1.0.0     backports_1.1.3  jsonlite_1.6    
## [33] hms_0.4.2        digest_0.6.18    stringi_1.4.3    keyring_1.1.0   
## [37] grid_3.5.2       cli_1.1.0        tools_3.5.2      magrittr_1.5    
## [41] lazyeval_0.2.2   crayon_1.3.4     pkgconfig_2.0.2  rsconnect_0.8.13
## [45] xml2_1.2.0       lubridate_1.7.4  assertthat_0.2.1 rmarkdown_1.12  
## [49] httr_1.4.0       rstudioapi_0.10  R6_2.4.0         nlme_3.1-137    
## [53] compiler_3.5.2</code></pre>
<p></small></p>
</section></section>
    </div>
  </div>

  <script src="libs/reveal.js-3.3.0.1/lib/js/head.min.js"></script>
  <script src="libs/reveal.js-3.3.0.1/js/reveal.js"></script>

  <script>

      // Full list of configuration options available at:
      // https://github.com/hakimel/reveal.js#configuration
      Reveal.initialize({
        // Display the page number of the current slide
        slideNumber: true,
        // Push each slide change to the browser history
        history: true,
        // Vertical centering of slides
        center: true,
        // Enables touch navigation on devices with touch input
        touch: true,
        // Opens links in an iframe preview overlay
        previewLinks: false,
        // Transition style
        transition: 'none', // none/fade/slide/convex/concave/zoom
        // Transition style for full page slide backgrounds
        backgroundTransition: 'default', // none/fade/slide/convex/concave/zoom



        // Optional reveal.js plugins
        dependencies: [
          { src: 'libs/reveal.js-3.3.0.1/plugin/notes/notes.js', async: true },
          { src: 'libs/reveal.js-3.3.0.1/plugin/zoom-js/zoom.js', async: true },
        ]
      });
    </script>
  <!-- dynamically load mathjax for compatibility with self-contained -->
  <script>
    (function () {
      var script = document.createElement("script");
      script.type = "text/javascript";
      script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
      document.getElementsByTagName("head")[0].appendChild(script);
    })();
  </script>

<script>
  (function() {
    if (window.jQuery) {
      Reveal.addEventListener( 'slidechanged', function(event) {  
        window.jQuery(event.previousSlide).trigger('hidden');
        window.jQuery(event.currentSlide).trigger('shown');
      });
    }
  })();
</script>


  </body>
</html>
